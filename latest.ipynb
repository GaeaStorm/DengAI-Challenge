{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']= (8,8)\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "\n",
    "train_labels = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "train_labels = train_labels.total_cases\n",
    "\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')\n",
    "\n",
    "submission = pd.read_csv('./data/submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([train_labels, train_features], axis=1)\n",
    "train_sj = train_set[train_set.city == 'sj'].copy()\n",
    "train_iq = train_set[train_set.city == 'iq'].copy()\n",
    "\n",
    "ytrain_sj = train_sj['total_cases'].copy()\n",
    "ytrain_iq = train_iq['total_cases'].copy()\n",
    "\n",
    "test_sj = test_features[train_set.city == 'sj'].copy()\n",
    "test_iq = test_features[train_set.city == 'iq'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['weekofyear','city', 'year']\n",
    "\n",
    "sj_features = ['reanalysis_dew_point_temp_k', 'reanalysis_precip_amt_kg_per_m2', 'reanalysis_specific_humidity_g_per_kg', \n",
    "            'reanalysis_avg_temp_k',  'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k']\n",
    "\n",
    "iq_features = ['reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k', 'reanalysis_avg_temp_k', 'precipitation_amt_mm', \n",
    "                 'reanalysis_dew_point_temp_k', 'reanalysis_air_temp_k', 'reanalysis_relative_humidity_percent',\n",
    "                 'reanalysis_precip_amt_kg_per_m2', 'ndvi_se', 'ndvi_ne', 'station_precip_mm']\n",
    "\n",
    "sj_all_features = list( set(sj_features).union(set(keys)) )\n",
    "iq_all_features = list( set(iq_features).union(set(keys)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sj = train_sj[sj_all_features]\n",
    "train_iq = train_iq[iq_all_features]\n",
    "test_sj = test_sj[sj_all_features]\n",
    "test_iq = test_iq[iq_all_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sj.fillna(method='ffill', inplace=True)\n",
    "train_iq.fillna(method='ffill', inplace=True)\n",
    "test_sj.fillna(method='ffill', inplace=True)\n",
    "test_iq.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sj[sj_features] = train_sj[sj_features].apply(normalize, axis=0)\n",
    "train_iq[iq_features] = train_iq[iq_features].apply(normalize, axis=0)\n",
    "test_sj[sj_features] = test_sj[sj_features].apply(normalize, axis=0)\n",
    "test_iq[iq_features] = test_iq[iq_features].apply(normalize, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrn_sj, Xtst_sj, Ytrn_sj, Ytst_sj = train_test_split(train_sj, ytrain_sj, test_size=0.2, stratify=train_sj.weekofyear)\n",
    "Xtrn_iq, Xtst_iq, Ytrn_iq, Ytst_iq = train_test_split(train_iq, ytrain_iq, test_size=0.2, stratify=train_iq.weekofyear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_sub = Xtst_sj[['city','year']]\n",
    "iq_sub = Xtst_iq[['city','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrn_sj = Xtrn_sj.drop(['city','year'],axis=1)\n",
    "Xtst_sj = Xtst_sj.drop(['city','year'],axis=1)\n",
    "Xtrn_iq = Xtrn_iq.drop(['city','year'],axis=1)\n",
    "Xtst_iq = Xtst_iq.drop(['city','year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cross_val(reg, X, Y, param_grid, scoring='neg_mean_absolute_error'):\n",
    "    grid = GridSearchCV(reg, param_grid=param_grid, scoring=scoring)\n",
    "    grid.fit(X, Y)\n",
    "    print( \"Best score: {}\".format(np.abs(grid.best_score_)))\n",
    "    print( \"Best params: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Juan\n",
      "Best score: 25.376366785062128\n",
      "Best params: {'max_depth': 3, 'n_estimators': 10}\n",
      "CPU times: user 31.2 s, sys: 330 ms, total: 31.5 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reg = RandomForestRegressor(random_state=67)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "      'n_estimators': [10, 30, 100, 300, 500, 1000], \n",
    "      'max_depth': [3, 5, 7, None]\n",
    "    } \n",
    "]\n",
    "\n",
    "print( \"San Juan\")\n",
    "grid_search_cross_val(reg, Xtrn_sj, Ytrn_sj, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_iq_model(train, test):\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_min_air_temp_k + reanalysis_avg_temp_k + reanalysis_max_air_temp_k + \" \\\n",
    "                    \"precipitation_amt_mm + reanalysis_dew_point_temp_k + reanalysis_air_temp_k + \" \\\n",
    "                    \"reanalysis_relative_humidity_percent + reanalysis_precip_amt_kg_per_m2 + \" \\\n",
    "                    \"ndvi_se + ndvi_ne + station_precip_mm\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)             \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "    \n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula, data=train, family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "    \n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula, data=full_dataset, family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iquitos\n",
      "best alpha =  1e-08\n",
      "best score =  7.105769230769231\n"
     ]
    }
   ],
   "source": [
    "iq_train_set = pd.concat([Ytrn_iq, Xtrn_iq], axis=1)\n",
    "iq_test_set = pd.concat([Ytst_iq, Xtst_iq], axis=1)\n",
    "\n",
    "print( \"Iquitos\")\n",
    "iq_model = get_best_iq_model(iq_train_set, iq_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                      n_jobs=None, oob_score=False, random_state=67, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sj = RandomForestRegressor(max_depth=3, n_estimators=30, random_state=67)\n",
    "reg_sj.fit(Xtrn_sj, Ytrn_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_sj = reg_sj.predict(Xtst_sj)\n",
    "ypred_sj = ypred_sj.round().astype(int)\n",
    "sj_pred = pd.DataFrame({'Prediction': ypred_sj, 'Actual' : Ytst_sj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_pred = pd.DataFrame({'Prediction': iq_model.fittedvalues, 'Actual' : Ytst_iq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.concat([sj_pred, iq_pred], axis=0)\n",
    "predict_df.loc[predict_df.Prediction < 0, 'Prediction'] = 0\n",
    "predict_df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_calc(test, predicted):\n",
    "    return (np.abs(test - predicted).sum())/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.165590397332993"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_calc(predict_df.Actual, predict_df.Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sj = test_sj[['city','year']]\n",
    "sub_iq = test_iq[['city','year']]\n",
    "\n",
    "test_sj = test_sj.drop(['city','year'],axis=1)\n",
    "test_iq = test_iq.drop(['city','year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_pred_final = iq_model.predict(test_iq)\n",
    "sj_pred_final = reg_sj.predict(test_sj)\n",
    "\n",
    "iq_sub_final = pd.DataFrame({'total_cases': iq_pred_final, 'city' : sub_iq.city, \n",
    "                             'year' : sub_iq.year, 'weekofyear' : test_iq.weekofyear})\n",
    "sj_sub_final = pd.DataFrame({'total_cases': sj_pred_final, 'city' : sub_sj.city, \n",
    "                             'year' : sub_sj.year, 'weekofyear' : test_sj.weekofyear})\n",
    "\n",
    "predict_final = pd.concat([sj_sub_final, iq_sub_final], axis=0)\n",
    "predict_final.total_cases = predict_final.total_cases.astype(int)\n",
    "predict_final.loc[predict_final.total_cases < 0, 'total_cases'] = 0\n",
    "predict_final.total_cases.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv('data/submission_format.csv')\n",
    "benchmark['total_cases'] = predict_final['total_cases'].values\n",
    "benchmark.to_csv('benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
