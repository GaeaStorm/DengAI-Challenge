{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']= (8,8)\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('./data/dengue_features_train.csv', index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('./data/dengue_labels_train.csv', index_col=[0,1,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "Preprocess data into features required for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_features, train_labels=None):\n",
    "    df = train_features.copy()\n",
    "    \n",
    "    features = ['station_max_temp_c', \n",
    "                 'station_min_temp_c', \n",
    "                 'station_avg_temp_c', \n",
    "                 'precipitation_amt_mm', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'reanalysis_air_temp_k', \n",
    "                 'reanalysis_relative_humidity_percent',\n",
    "                 'reanalysis_precip_amt_kg_per_m2', \n",
    "                 'ndvi_se', \n",
    "                 'ndvi_ne', \n",
    "                 'station_precip_mm']\n",
    "    \n",
    "    df = df[features]\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    \n",
    "    if train_labels is not None:\n",
    "        labels = train_labels\n",
    "        df = df.join(labels)\n",
    "        \n",
    "   \n",
    "    celsius_list = ['station_max_temp_c', 'station_min_temp_c', 'station_avg_temp_c' ]\n",
    "    for col in celsius_list:\n",
    "        df[col] = df[col] + 273.15\n",
    "    df = df.rename(columns = { name : name[:-2] + '_k' for name in celsius_list })\n",
    "    sj = df.loc['sj']\n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return sj, iq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against(sj_pred, iq_pred):\n",
    "    figs, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "    # plot sj\n",
    "    sj_pred.plot(ax=axes[0], label=\"Predictions\")\n",
    "    sj_train.total_cases.plot(ax=axes[0], label=\"Actual\")\n",
    "\n",
    "    # plot iq\n",
    "    iq_pred.plot(ax=axes[1], label=\"Predictions\")\n",
    "    iq_train.total_cases.plot(ax=axes[1], label=\"Actual\")\n",
    "\n",
    "    plt.suptitle(\"Dengue Predicted Cases vs. Actual Cases\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_calc(test, predicted):\n",
    "    return (np.abs(test - predicted).sum())/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_benchmark(sj_predictions, iq_predictions):\n",
    "    submission = pd.read_csv('./data/submission_format.csv', index_col=[0,1,2])\n",
    "    submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "    submission.to_csv(\"benchmark.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "Split into Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train, iq_train = preprocess_data(train_features, train_labels)\n",
    "\n",
    "sj_train_subtrain = sj_train.head(800)\n",
    "sj_train_subtest = sj_train.tail(sj_train.shape[0] - 800)\n",
    "\n",
    "iq_train_subtrain = iq_train.head(400)\n",
    "iq_train_subtest = iq_train.tail(iq_train.shape[0] - 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel GLM Model\n",
    "GLM models with different features for San Juan and Iquitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sj_glm_model(train, test):\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_relative_humidity_percent + reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_min_temp_k + station_avg_temp_k\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "    \n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula, data=train, family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "    \n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula, data=full_dataset, family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iq_glm_model(train, test):\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"station_min_temp_k + station_avg_temp_k + station_max_temp_k + \" \\\n",
    "                    \"precipitation_amt_mm + reanalysis_dew_point_temp_k + reanalysis_air_temp_k + \" \\\n",
    "                    \"reanalysis_relative_humidity_percent + reanalysis_precip_amt_kg_per_m2 + \" \\\n",
    "                    \"ndvi_se + ndvi_ne + station_precip_mm\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)             \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "    \n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula, data=train, family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "    \n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula, data=full_dataset, family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def poly_rfr_model(train, test):\n",
    "    X = train.drop(columns=[\"total_cases\"])\n",
    "    y = train.total_cases\n",
    "\n",
    "    depth = range(1, 11)\n",
    "    n_estimator = [10, 30, 50, 80, 100, 300, 500, 800, 1000]\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=2, include_bias=True)\n",
    "    rfr = RandomForestRegressor(random_state=67)\n",
    "    pipeline_rfr = Pipeline([(\"polynomial_features\", polynomial_features), (\"rfr\", rfr)])\n",
    "\n",
    "    parameters = [{\"rfr__max_depth\":depth, \"rfr__n_estimators\":n_estimator}]\n",
    "    clf_rfr = GridSearchCV(pipeline_rfr, param_grid=parameters, cv=10, scoring='neg_mean_absolute_error')\n",
    "    clf_rfr.fit(X, y)\n",
    "\n",
    "    scores = clf_rfr.cv_results_['mean_test_score']\n",
    "    scores_std = clf_rfr.cv_results_['std_test_score']\n",
    "    std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "    print(\"Best depth for Random Forest is\", clf_rfr.best_params_['rfr__max_depth'])\n",
    "    print(\"Best number of neighbours for Random Forest is\", clf_rfr.best_params_['rfr__n_estimators'])\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    rfr = RandomForestRegressor(random_state=67, max_depth=clf_rfr.best_params_['rfr__max_depth'], n_estimators=clf_rfr.best_params_['rfr__n_estimators'])\n",
    "    pipeline_rfr = Pipeline([(\"polynomial_features\", polynomial_features), (\"rfr\", rfr)])\n",
    "    pipeline_rfr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(train, test):\n",
    "    X = train.drop(columns=['total_cases'])\n",
    "    Y = train.total_cases\n",
    "    \n",
    "    reg = RandomForestRegressor(random_state=67)\n",
    "    param_grid = [{\n",
    "      'n_estimators': [10, 30, 100, 300, 500, 1000], \n",
    "      'max_depth': [3, 5, 7, None]\n",
    "    }]\n",
    "    grid = GridSearchCV(reg, param_grid=param_grid, scoring='neg_mean_absolute_error')\n",
    "    grid.fit(X, Y)\n",
    "    \n",
    "    print(\"Best score: {}\".format(np.abs(grid.best_score_)))\n",
    "    print(\"Best params: {}\".format(grid.best_params_))\n",
    "    \n",
    "    full_dataset = pd.concat([train, test])\n",
    "    reg = RandomForestRegressor(random_state=67, max_depth=grid.best_params_['max_depth'], n_estimators=grid.best_params_['n_estimators'])\n",
    "    reg.fit(X, Y)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_knn_model(train, test):\n",
    "    X = train.drop(columns=['total_cases'])\n",
    "    Y = train.total_cases\n",
    "\n",
    "    k_neighbours = range(1, 26)\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=2, include_bias=True)\n",
    "    knn = KNeighborsRegressor()\n",
    "    pipeline_knn = Pipeline([(\"polynomial_features\", polynomial_features), (\"knn\", knn)])\n",
    "\n",
    "    parameters = [{\"knn__n_neighbors\":k_neighbours}]\n",
    "\n",
    "    clf_knn = GridSearchCV(pipeline_knn, param_grid=parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "    clf_knn.fit(X, Y)\n",
    "\n",
    "    scores = clf_knn.cv_results_['mean_test_score']\n",
    "    scores_std = clf_knn.cv_results_['std_test_score']\n",
    "    std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "    print(\"Best k for kNN is\", clf_knn.best_params_['knn__n_neighbors'])\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    knn = KNeighborsRegressor(n_neighbors=clf_knn.best_params_['knn__n_neighbors'])\n",
    "    pipeline_knn = Pipeline([(\"polynomial_features\", polynomial_features), (\"knn\", knn)])\n",
    "    pipeline_knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneighbours_model(train, test):\n",
    "    X = train.drop(columns=['total_cases'])\n",
    "    Y = train.total_cases\n",
    "    \n",
    "    k_neighbours = range(1, 26)\n",
    "    \n",
    "    reg = KNeighborsRegressor(random_state=67)\n",
    "    param_grid = [{\"n_neighbors\":k_neighbours}]\n",
    "    grid = GridSearchCV(reg, param_grid=param_grid, scoring='neg_mean_absolute_error')\n",
    "    grid.fit(X, Y)\n",
    "    \n",
    "    print(\"Best score: {}\".format(np.abs(grid.best_score_)))\n",
    "    print(\"Best params: {}\".format(grid.best_params_))\n",
    "    \n",
    "    full_dataset = pd.concat([train, test])\n",
    "    reg = KNeighborsRegressor(random_state=67, n_neighbors=grid.best_params_['n_neighbors'])\n",
    "    reg.fit(X, Y)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "Checks results of models by plotting against actual values and calculating the Mean Absolute Error for the individual models and together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"GLM\", \"Poly RFR\", \"RFR\", \"Poly KNN\", \"KNN\"]\n",
    "sj_models_mae = []\n",
    "iq_models_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  1e-08\n",
      "best score =  21.698529411764707\n",
      "best alpha =  1e-08\n",
      "best score =  6.991666666666666\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'fitted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1b5ca616b719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_iq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miq_best_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfittedvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_against\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miq_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msj_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'fitted'"
     ]
    }
   ],
   "source": [
    "sj_best_model = sj_glm_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = iq_glm_model(iq_train_subtrain, iq_train_subtest)\n",
    "pred_sj = sj_best_model.fittedvalues\n",
    "pred_iq = iq_best_model.fittedvalues\n",
    "\n",
    "plot_against(pred_sj, iq_train.fitted)\n",
    "\n",
    "sj_mae = mae_calc(pred_sj, sj_train.total_cases)\n",
    "sj_models_mae.append(sj_mae)\n",
    "print(\"San Juan MAE:\", sj_mae)\n",
    "iq_mae = mae_calc(pred_iq, iq_train.total_cases)\n",
    "iq_models_mae.append(iq_mae)\n",
    "print(\"Iquitos MAE:\", iq_mae)\n",
    "total_mae = (np.abs(pred_sj - sj_train.total_cases).sum() + \n",
    "             np.abs(pred_iq - iq_train.total_cases).sum()) / (sj_train.shape[0] + iq_train.shape[0])\n",
    "print(\"Total MAE:\", total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_best_model = poly_rfr_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = poly_rfr_model(iq_train_subtrain, iq_train_subtest)\n",
    "pred_sj = sj_best_model.predict(sj_train.drop(columns=[\"total_cases\"]))\n",
    "pred_iq = iq_best_model.predict(iq_train.drop(columns=[\"total_cases\"]))\n",
    "\n",
    "plot_against(pred_sj, iq_train.fitted)\n",
    "\n",
    "sj_mae = mae_calc(pred_sj, sj_train.total_cases)\n",
    "sj_models_mae.append(sj_mae)\n",
    "print(\"San Juan MAE:\", sj_mae)\n",
    "iq_mae = mae_calc(pred_iq, iq_train.total_cases)\n",
    "iq_models_mae.append(iq_mae)\n",
    "print(\"Iquitos MAE:\", iq_mae)\n",
    "total_mae = (np.abs(pred_sj - sj_train.total_cases).sum() + \n",
    "             np.abs(pred_iq - iq_train.total_cases).sum()) / (sj_train.shape[0] + iq_train.shape[0])\n",
    "print(\"Total MAE:\", total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_best_model = random_forest_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = random_forest_model(iq_train_subtrain, iq_train_subtest)\n",
    "pred_sj = sj_best_model.predict(sj_train.drop(columns=[\"total_cases\"]))\n",
    "pred_iq = iq_best_model.predict(iq_train.drop(columns=[\"total_cases\"]))\n",
    "\n",
    "plot_against(pred_sj, iq_train.fitted)\n",
    "\n",
    "sj_mae = mae_calc(pred_sj, sj_train.total_cases)\n",
    "sj_models_mae.append(sj_mae)\n",
    "print(\"San Juan MAE:\", sj_mae)\n",
    "iq_mae = mae_calc(pred_iq, iq_train.total_cases)\n",
    "iq_models_mae.append(iq_mae)\n",
    "print(\"Iquitos MAE:\", iq_mae)\n",
    "total_mae = (np.abs(pred_sj - sj_train.total_cases).sum() + \n",
    "             np.abs(pred_iq - iq_train.total_cases).sum()) / (sj_train.shape[0] + iq_train.shape[0])\n",
    "print(\"Total MAE:\", total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_best_model = poly_knn_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = poly_knn_model(iq_train_subtrain, iq_train_subtest)\n",
    "pred_sj = sj_best_model.predict(sj_train.drop(columns=[\"total_cases\"]))\n",
    "pred_iq = iq_best_model.predict(iq_train.drop(columns=[\"total_cases\"]))\n",
    "\n",
    "plot_against(pred_sj, iq_train.fitted)\n",
    "\n",
    "sj_mae = mae_calc(pred_sj, sj_train.total_cases)\n",
    "sj_models_mae.append(sj_mae)\n",
    "print(\"San Juan MAE:\", sj_mae)\n",
    "iq_mae = mae_calc(pred_iq, iq_train.total_cases)\n",
    "iq_models_mae.append(iq_mae)\n",
    "print(\"Iquitos MAE:\", iq_mae)\n",
    "total_mae = (np.abs(pred_sj - sj_train.total_cases).sum() + \n",
    "             np.abs(pred_iq - iq_train.total_cases).sum()) / (sj_train.shape[0] + iq_train.shape[0])\n",
    "print(\"Total MAE:\", total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_best_model = kneighbours_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = kneighbours_model(iq_train_subtrain, iq_train_subtest)\n",
    "pred_sj = sj_best_model.predict(sj_train.drop(columns=[\"total_cases\"]))\n",
    "pred_iq = iq_best_model.predict(iq_train.drop(columns=[\"total_cases\"]))\n",
    "\n",
    "plot_against(pred_sj, iq_train.fitted)\n",
    "\n",
    "sj_mae = mae_calc(pred_sj, sj_train.total_cases)\n",
    "sj_models_mae.append(sj_mae)\n",
    "print(\"San Juan MAE:\", sj_mae)\n",
    "iq_mae = mae_calc(pred_iq, iq_train.total_cases)\n",
    "iq_models_mae.append(iq_mae)\n",
    "print(\"Iquitos MAE:\", iq_mae)\n",
    "total_mae = (np.abs(pred_sj - sj_train.total_cases).sum() + \n",
    "             np.abs(pred_iq - iq_train.total_cases).sum()) / (sj_train.shape[0] + iq_train.shape[0])\n",
    "print(\"Total MAE:\", total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_map = pd.DataFrame()\n",
    "error_map[\"models\"] = models\n",
    "error_map[\"sj_mae\"] = sj_models_mae\n",
    "error_map[\"iq_mae\"] = iq_models_mae\n",
    "sns.barplot(x=error_map.models, y=error_map.sj_mae)\n",
    "plt.show()\n",
    "sns.barplot(x=error_map.models, y=error_map.iq_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set\n",
    "Predicts on the test set given and saves predictions to benchmark.csv using the submission format given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('./data/dengue_features_test.csv', index_col=[0,1,2])\n",
    "sj_test, iq_test = preprocess_data(test_features)\n",
    "\n",
    "sj_predictions = sj_best_model.predict(sj_test).astype(int)\n",
    "iq_predictions = iq_best_model.predict(iq_test).astype(int)\n",
    "save_benchmark(sj_predictions, iq_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
